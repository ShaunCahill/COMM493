{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c09b6b-080d-4f8f-a1ef-18b5045faafc",
   "metadata": {},
   "source": [
    "# For this lab we will be using the following dataset to predict if the text belongs to __label__1 or __label__2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd42cb79-fc81-4e29-85e3-cef5cb4961d2",
   "metadata": {},
   "source": [
    "# STEP 1 - SETUP THE JUPYTER NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498841f7-ece5-4ed5-b228-07017bae9ec3",
   "metadata": {},
   "source": [
    "## First we update the SageMaker environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59b33a1-9866-4769-bcef-9ddecdee5ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -qU --upgrade boto3\n",
    "%pip install -qU --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f9ce4b-2b0c-4940-963a-779d2c9520cd",
   "metadata": {},
   "source": [
    "## Now we install the libraries that we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584afedf-98a0-42bc-a43d-2c8fc4fdc69d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator \n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "from sagemaker import image_uris\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25dc4b4-3192-49c8-824a-1712f6a6a8c8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now we download the Natural Language Toolkit: Punkt sentence tokenizer to tokenize the words and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f6b904-2dd7-409d-9ff1-67466e3a9de6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c48f7-d9c9-4289-beef-74deb9c778be",
   "metadata": {},
   "source": [
    "## Now we will download the list of stopwords from Natural Language Toolkit so that we can use it to remove the stopwords in our sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2106c6-c781-49fc-b055-c73f7cf2eb05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ed5c9-685b-44d8-a579-203c67ef5b84",
   "metadata": {},
   "source": [
    "## Now we setup our SageMaker Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97abda33-8798-4732-9e36-705ff86ce56e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "sess = sagemaker.Session() \n",
    "region = sess.boto_session.region_name\n",
    "bucket = sess.default_bucket()\n",
    "print(\"The role is \", role)\n",
    "print(\"The session is \", sess)\n",
    "print(\"The region is \", region)\n",
    "print(\"The bucket is \", bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6eee40a-7b19-4ea2-9f7d-0ea5ab60c152",
   "metadata": {},
   "source": [
    "# STEP 2 - PRE PROCESS THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1be79b6-6892-4bea-8ba3-1779c013f2cc",
   "metadata": {},
   "source": [
    "## In this step your job is to convert the dataset into the following format.   \n",
    "\n",
    "## _ _ label _ _ {label name} [space] {Text from the dataset that has been identified as the label}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be2654-6a90-4808-95dd-c6cc1e37ca04",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Lets take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3599c9f0-0d5a-4026-9cd8-ef42801e8556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the data into a pandas DataFrame\n",
    "\n",
    "amazon_df = pd.read_csv(\"Amazon_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ddfe4-aee6-4eba-9f46-d547dd3bfe79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Look at the data\n",
    "\n",
    "amazon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b3fea0-9a91-4b89-8f40-53c2d2ebd4d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Now let's tokenize the column \"Review\".\n",
    "\n",
    "### Note that the column review is turned into a LIST of words and we will need to cahnge that back to a text string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5058bd-8341-419f-b251-893c2a3db791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use NTLK word_tokenize to seperate the sentence into words\n",
    "\n",
    "amazon_df['Review'] = amazon_df['Review'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8090e38d-57d9-4857-97c0-97353c919b31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(amazon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6f77b-17ef-442d-a22e-9abc0e742f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The results create a list in the message column and we will use apply, join and lanbda to replace the list with a string\n",
    "\n",
    "amazon_df['Review'] = amazon_df['Review'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1fe1a0-c437-4441-9805-79a68af1c3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Look at the data\n",
    "\n",
    "amazon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba3d919-b5d2-4970-9d73-1ba943c5016d",
   "metadata": {},
   "source": [
    "### Notice now how we are back to a string of text an it is not a list of words\n",
    "\n",
    "### Now lets turn all the letters to lower case before we remove the stop words because the stop words are all lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aed6b4-2cc7-4db3-83ab-5bbc29a59585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will convert the case of each word to lower case to simplify the removal. ie: The, THE and the all equal the\n",
    "\n",
    "amazon_df['Review'] = amazon_df['Review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d06a40-4899-43a6-b6a4-4674db80cab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Look at the data\n",
    "\n",
    "amazon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936684e5-d882-40bb-9aed-ae26134365f3",
   "metadata": {},
   "source": [
    "### Now let's remove all the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc50fcc-ba8c-4920-9048-6913e5488616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using Apply, lambda and a For loop remove all the stop words\n",
    "# word for word in x.split() - Split the first message into words and run the loop for each word\n",
    "# if the word is not in teh stopword list use the join method to put it back in the sentence\n",
    "\n",
    "amazon_df['Review'] = amazon_df['Review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9060bd-d408-4d3f-95dd-139fa2f64b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Look at the data\n",
    "\n",
    "amazon_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240a8124-826c-4d87-9785-e084545b7d22",
   "metadata": {},
   "source": [
    "### Now that the column \"Review\" is in the right format we can now create the Training and Validation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aadb78-3f4f-4eeb-b96d-4870520d2c71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shuffle and Split the data into 80% training and 20% validating\n",
    "\n",
    "train_data, validate_data = train_test_split(amazon_df, test_size=0.2)\n",
    "\n",
    "# Convert dataframes to TEXT files and save them locally to the notebook and make sure to exclude the headers so that BlazingText will accept the file\n",
    "\n",
    "train_data.to_csv('Amazon_text.train', sep=' ', header=False, index=False, quotechar=\" \")\n",
    "validate_data.to_csv('Amazon_text.validate', sep=' ', header=False, index=False, quotechar=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2357f4a0-028e-4914-8dd0-ad6e0b34367c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now copy the files to the S3 bucket in the appropriate folders so the model can find the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5f4f91-2461-41dc-a4b6-27847704f96f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the file to your S3 bucket using sess.upload_data\n",
    "# You will need to pass the file to be uploaded, a prefix (top level folder to store the data) and the subfolders\n",
    "# Here we will also define the output folder for the results\n",
    "# Note I did not call them .csv because the are not csv files but text files\n",
    "\n",
    "prefix = 'Amazon_text'\n",
    "training_data_path = sess.upload_data( path='Amazon_text.train', key_prefix=prefix + '/input/train') \n",
    "validation_data_path = sess.upload_data( path='Amazon_text.validate', key_prefix=prefix + '/input/validate')\n",
    "output_data_path = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print(training_data_path)\n",
    "print(validation_data_path)\n",
    "print(output_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c2304-8145-4bbf-812b-adff78c186f9",
   "metadata": {},
   "source": [
    "# STEP 3 - This is where you will Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395dc741-4596-47a3-a9f1-d7b4b17c5fa0",
   "metadata": {},
   "source": [
    "## Tell SageMaker which pre-built Docker image to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58652600-b382-4d22-94a9-e2ae0b0e59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/image_uris.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48246e4a-7e0d-40b3-b885-cf75b9a76516",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tell SageMaker where the data is located\n",
    "## Hint remember that we copied it to the S3 bucket above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84430f66-3acd-4f3f-8c9c-20eb4bc0cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/inputs.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9741d299-0161-4d16-8010-a3554657a241",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create the Estimator and apply only the required hyperaprameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b090e07f-0025-4f8e-b327-ce492d50b4be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#  ESTIMATOR  https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html\n",
    "#  HYPERPARAMETERS  https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext_hyperparameters.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b299d798-0943-4de9-b6af-17245e0d4540",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Launch the training job without hyperparameter tuning so that we can compare the results after hyperparameter tuning. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f35c459-7175-4956-92fd-1e7d75a17f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96882b7e-b6e8-4c39-ad95-ada8200f8be9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## When the training is done it will report the Training Accuracy and Validation Accuracy. Make note of each so that we can see the different"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccafa43-7251-4e34-8ec8-475780eb7c11",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Now lets tune some Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eecd2c6-d1e5-4172-83fa-6711c4be1f40",
   "metadata": {},
   "source": [
    "## Set the Hyperparameter tuning dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c401fafd-0219-49ee-bfa3-9a18596a9655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the blazingtext hyperparameter dictonary\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.Estimator.set_hyperparameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d7279-dde3-49a2-a9c0-85c23b21701b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define the interaction with Amazon SageMaker hyperparameter tuning job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade0d763-2f2f-4c27-9b04-ca736363f4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html\n",
    "\n",
    "# Take the time to review and choose an objective you want to target\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext-tuning.html\n",
    "\n",
    "# Take the time to review the tunable hyperparameters and try some different ones. \n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext-tuning.html\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa319c-dc50-4485-b7b7-2fc576831dbb",
   "metadata": {},
   "source": [
    "## Start the tuning Jobs\n",
    "## Note: we already did this earlier when we trained our first job. We are going to do it again but with using HyperparameterTuner instead of Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae435b2-abe1-4b8f-a4a8-0c6774d8aca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html#sagemaker.tuner.HyperparameterTuner.fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c77e5ba-eeb0-42ac-b416-0075e0a1e32f",
   "metadata": {},
   "source": [
    "## When the training is done print out the best values for each parameter to included. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c91d3-459a-4fe0-a69b-9da92e124d10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html#sagemaker.tuner.HyperparameterTuner.best_training_job\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3806cd4c-7b17-4480-b73f-7e478c252cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Launch a new training job with the new hyperparameter values you just printed out\n",
    "\n",
    "## Hint repeat the step earlier where you ran the training job with only the required hyparameters and now include the ones you chose in the hyperparameter training and use the values you printed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144abaf-ef5b-47be-83c4-be8b303a493d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase.fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db1393-407b-4204-8e2a-ed06cb63d75d",
   "metadata": {},
   "source": [
    "## Take note of the different in the Training and Validation accuracy, did they imporve or get worse?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf3cb6b-42e6-42d5-b1cf-30d1aa4a36f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deploy and Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3fb36b-5076-4493-b9b3-ff420fdd98ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Choose the model you want to use from the training session and load it to a variable. This should be the model from the last trainign session and you can use .model_data to load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d389ee52-3cfd-47d3-8d62-f0003a01b378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# {variable Name} = {ModelName}.model_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f46d6c-5aa5-4bf9-af9b-1f2203b5e671",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tell SageMaker which docker container image to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415e088-57d2-49a2-9c17-0368a25bb724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateModel.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93c5ad4-054c-4d1b-95e8-76564ffa99bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## To host your model, you create an endpoint configuration with the CreateEndpointConfig API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b216a9-e17e-4ebf-9265-ac3d1eb63a61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateEndpointConfig.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86051f45-60d0-4da8-9e5c-18382c21b22a",
   "metadata": {},
   "source": [
    "## and then create an endpoint with the CreateEndpoint API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7cea74-a193-42c9-a10f-899407fe57c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_CreateEndpoint.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67abab23-aa69-44d8-a00d-52028e6591e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Once the Endpoint has been deployed make an inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483eac4-e12d-4e14-ac4f-6b7ee7e14c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_runtime_InvokeEndpoint.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f3183-646b-4862-9f81-fc493bdd8097",
   "metadata": {},
   "source": [
    "## Don't forget to delete your model, endpoint configuration and endpoint to preserve your budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12437e7-7d51-48bf-b62f-a40a606c9682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-delete-resources.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
